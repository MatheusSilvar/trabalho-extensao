import networkx as nx
import matplotlib.pyplot as plt
import re
from collections import Counter
import streamlit as st

# Lista de palavras-chave espec√≠ficas para PUC Campinas
LISTA_PALAVRAS_CHAVES = [
    # Cursos e √°reas acad√™micas
    "curso", "cursos", "gradua√ß√£o", "p√≥s-gradua√ß√£o", "mestrado", "doutorado",
    "engenharia", "direito", "medicina", "psicologia", "administra√ß√£o", "economia",
    "arquitetura", "design", "comunica√ß√£o", "jornalismo", "publicidade", "marketing",
    
    # Processo seletivo e ingresso
    "vestibular", "enem", "sisu", "prouni", "fies", "nota", "notas", "prova", "provas",
    "inscri√ß√£o", "inscri√ß√µes", "matr√≠cula", "rematr√≠cula", "transfer√™ncia", "transfer√™ncias",
    
    # Estrutura acad√™mica
    "campus", "laborat√≥rio", "laborat√≥rios", "biblioteca", "sala", "salas", "audit√≥rio",
    "restaurante", "cantina", "estacionamento", "quadra", "gin√°sio",
    
    # Ensino e aprendizagem
    "disciplina", "disciplinas", "mat√©ria", "mat√©rias", "professor", "professores",
    "aula", "aulas", "presencial", "ead", "online", "dist√¢ncia", "h√≠brido",
    "nota", "m√©dia", "frequ√™ncia", "aprova√ß√£o", "reprova√ß√£o", "dp",
    
    # Documentos e servi√ßos
    "hist√≥rico", "diploma", "certificado", "declara√ß√£o", "atestado", "comprovante",
    "boleto", "mensalidade", "taxa", "desconto", "bolsa", "financiamento",
    
    # Apoio ao estudante
    "caa", "atendimento", "secretaria", "ouvidoria", "monitoria", "est√°gio", "tcc",
    "inicia√ß√£o", "cient√≠fica", "pesquisa", "extens√£o", "interc√¢mbio",
    
    # Tecnologia e sistemas
    "portal", "sistema", "login", "senha", "email", "plataforma", "ambiente", "virtual",
    
    # Localiza√ß√£o e contato
    "campinas", "endere√ßo", "telefone", "contato", "hor√°rio", "funcionamento",
    
    # Outros termos relevantes
    "aluno", "aluna", "estudante", "universit√°rio", "acad√™mico", "semestre", "per√≠odo"
]

def limpar_texto(texto):
    """Remove pontua√ß√µes e transforma em min√∫sculas"""
    return re.sub(r"[^\w\s]", "", texto.lower())

def extrair_palavras_chave(texto, lista_palavras):
    """Extrai palavras-chave do texto que est√£o na lista"""
    texto_limpo = limpar_texto(texto)
    palavras_texto = texto_limpo.split()
    return [palavra for palavra in palavras_texto if palavra in lista_palavras]

def criar_grafo_conversa(mensagens_chat, lista_palavras_chaves=None):
    """
    Cria um grafo a partir das mensagens do chat atual.
    Cada n√≥ √© uma palavra-chave e as arestas representam coocorr√™ncia na mesma mensagem.
    
    Args:
        mensagens_chat: lista de dicion√°rios com 'role' e 'content'
        lista_palavras_chaves: lista de palavras-chave para filtrar (opcional)
    
    Returns:
        tuple: (grafo networkx.Graph, lista de palavras encontradas)
    """
    if lista_palavras_chaves is None:
        lista_palavras_chaves = LISTA_PALAVRAS_CHAVES
    
    G = nx.Graph()
    todas_palavras = []
    
    # Processar cada mensagem
    for mensagem in mensagens_chat:
        conteudo = mensagem.get("content", "")
        palavras_encontradas = extrair_palavras_chave(conteudo, lista_palavras_chaves)
        todas_palavras.extend(palavras_encontradas)
        
        # Adicionar n√≥s e arestas baseados na coocorr√™ncia
        for i, palavra1 in enumerate(palavras_encontradas):
            G.add_node(palavra1)
            for j in range(i + 1, len(palavras_encontradas)):
                palavra2 = palavras_encontradas[j]
                if palavra1 != palavra2:
                    if G.has_edge(palavra1, palavra2):
                        G[palavra1][palavra2]['weight'] += 1
                    else:
                        G.add_edge(palavra1, palavra2, weight=1)
    
    return G, todas_palavras

def plotar_grafo_conversa(chat_messages):
    """
    Plota o grafo das palavras-chave da conversa atual usando Streamlit
    
    Args:
        chat_messages: lista de mensagens do chat atual
    """
    if not chat_messages:
        st.warning("‚ö†Ô∏è Nenhuma mensagem encontrada no chat atual!")
        return
    
    # Criar grafo
    G, palavras_encontradas = criar_grafo_conversa(chat_messages)
    
    if not G.nodes():
        st.warning("‚ö†Ô∏è Nenhuma palavra-chave relevante encontrada na conversa!")
        return
    
    # Estat√≠sticas
    contador_palavras = Counter(palavras_encontradas)
    
    # Criar visualiza√ß√£o
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Grafo de palavras-chave
    pos = nx.spring_layout(G, k=1, iterations=50)
    
    # Tamanho dos n√≥s baseado na frequ√™ncia
    node_sizes = [contador_palavras[node] * 300 for node in G.nodes()]
    
    # Espessura das arestas baseada no peso
    edge_weights = [G[u][v].get('weight', 1) for u, v in G.edges()]
    
    nx.draw(G, pos, ax=ax1, 
            with_labels=True, 
            node_color='lightblue',
            node_size=node_sizes,
            font_size=8,
            font_weight='bold',
            edge_color='gray',
            width=[w * 0.5 for w in edge_weights])
    
    ax1.set_title(f"Grafo de Palavras-chave\n({len(G.nodes())} termos encontrados)", 
                  fontsize=12, fontweight='bold')
    
    # Gr√°fico de barras das palavras mais frequentes
    palavras_top = contador_palavras.most_common(10)
    if palavras_top:
        palavras, frequencias = zip(*palavras_top)
        ax2.barh(range(len(palavras)), frequencias, color='lightcoral')
        ax2.set_yticks(range(len(palavras)))
        ax2.set_yticklabels(palavras)
        ax2.set_xlabel('Frequ√™ncia')
        ax2.set_title('Top 10 Palavras-chave', fontsize=12, fontweight='bold')
        ax2.invert_yaxis()
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Mostrar estat√≠sticas
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Palavras-chave √∫nicas", len(G.nodes()))
    with col2:
        st.metric("Conex√µes", len(G.edges()))
    with col3:
        st.metric("Total de ocorr√™ncias", len(palavras_encontradas))
    
    # Mostrar palavras mais relevantes
    if palavras_top:
        st.subheader("üîç Palavras-chave mais relevantes:")
        for palavra, freq in palavras_top[:5]:
            st.write(f"‚Ä¢ **{palavra}**: {freq} ocorr√™ncia(s)")

def obter_estatisticas_conversa(chat_messages):
    """
    Retorna estat√≠sticas b√°sicas da conversa
    
    Args:
        chat_messages: lista de mensagens do chat atual
    
    Returns:
        dict: dicion√°rio com estat√≠sticas
    """
    if not chat_messages:
        return {}
    
    G, palavras_encontradas = criar_grafo_conversa(chat_messages)
    contador_palavras = Counter(palavras_encontradas)
    
    return {
        "total_mensagens": len(chat_messages),
        "palavras_unicas": len(G.nodes()),
        "total_palavras_chave": len(palavras_encontradas),
        "conexoes": len(G.edges()),
        "palavra_mais_frequente": contador_palavras.most_common(1)[0] if contador_palavras else None,
        "top_5_palavras": contador_palavras.most_common(5)
    }

def exportar_dados_grafo(chat_messages, formato="json"):
    """
    Exporta dados do grafo em diferentes formatos
    
    Args:
        chat_messages: lista de mensagens do chat atual
        formato: "json", "csv" ou "txt"
    
    Returns:
        str: dados formatados
    """
    G, palavras_encontradas = criar_grafo_conversa(chat_messages)
    contador_palavras = Counter(palavras_encontradas)
    
    if formato == "json":
        import json
        dados = {
            "nos": list(G.nodes()),
            "arestas": list(G.edges()),
            "frequencias": dict(contador_palavras),
            "estatisticas": obter_estatisticas_conversa(chat_messages)
        }
        return json.dumps(dados, indent=2, ensure_ascii=False)
    
    elif formato == "csv":
        import csv
        import io
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(["Palavra", "Frequencia"])
        for palavra, freq in contador_palavras.most_common():
            writer.writerow([palavra, freq])
        return output.getvalue()
    
    elif formato == "txt":
        resultado = "AN√ÅLISE DA CONVERSA\n"
        resultado += "=" * 50 + "\n\n"
        resultado += f"Total de palavras-chave √∫nicas: {len(G.nodes())}\n"
        resultado += f"Total de conex√µes: {len(G.edges())}\n"
        resultado += f"Total de ocorr√™ncias: {len(palavras_encontradas)}\n\n"
        resultado += "PALAVRAS MAIS FREQUENTES:\n"
        resultado += "-" * 30 + "\n"
        for palavra, freq in contador_palavras.most_common(10):
            resultado += f"{palavra}: {freq} ocorr√™ncia(s)\n"
        return resultado
    
    return ""